# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Natural Language Processing I

---


---

## Learning Objectives

*After this lesson, students will be able to:*
1. Transform Textual Data to Numeric Representations
2. Differentiate between One Hot, Count, and Tfidf Vectorization
3. Use stopwords and n-grams to adjust feature representations
4. Build classification model with text as input.

---

## OPTIONAL: Resources for Practice and Learning

*For supplemental reading material on this topic, check out the following resources:*
- Text Analytics with Python by Dipanjan Sarkar
- ["The Great AI Awakening" by The New York Times Magazine](https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html)
- [Python RegEx library (re)](https://docs.python.org/3/library/re.html)
- [Regular Expressions Wikipedia Article](https://en.wikipedia.org/wiki/Regular_expression#Patterns_for_non-regular_languages)
- [RegEx Cheat Sheet](http://www.rexegg.com/regex-quickstart.html)
- [RegExr - Learn, Build, and Test your RegEx](https://regexr.com/)
- [Stanford NLP: Difference between Stemming and Lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)
- [Porter's Stemmer Algorithm Paper](https://www.cs.toronto.edu/~frank/csc2501/Readings/R2_Porter/Porter-1980.pdf)
- [Word Vectors!](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/)
- [Word2Vec in gensim](https://radimrehurek.com/gensim/models/word2vec.html)
- [Word2Vec in TensorFlow](https://www.tensorflow.org/tutorials/word2vec)
- [Wikipedia Article on Word2Vec](https://en.wikipedia.org/wiki/Word2vec)
---
